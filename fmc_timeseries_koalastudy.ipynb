{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this within dea-notebooks/ on the VDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('dea-notebooks/Scripts/') # i.e. dea-notebooks/Scripts/\n",
    "import datacube\n",
    "from dea_datahandling import load_ard\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "dc = datacube.Datacube(app='sentinel_fmc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load raster of study area and the look-up-table for FMC calculation (520,922,003 20x20m pixels equalling 208,369 km2, and 12 column x 4400 row dataframe respectively)\n",
    "2. Get datacube of Sentinel reflectance like the raster, for whole Sentinel timeseries (up to 2100 timestamps). Mask out raster koala_trees != 1 during or after getting reflectances? \n",
    "3. Calculate FMC using numpy with reflectance and LUT inputs\n",
    "4. Store datacube of only FMC variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LUT and select only relevant land cover ie forest\n",
    "file_path = '/g/data/xc0/user/IvanK/field site_fmc_estimation/'\n",
    "\n",
    "# read Look Up Table from file\n",
    "df = pd.read_csv(file_path+'LUT_S2.csv', index_col='ID')\n",
    "df = df.drop(columns=['lai','soil','n','443','490','1375','945'])\n",
    "df.columns = ['fmc','landcover','green','red','red_edge1',\n",
    "              'red_edge2','red_edge3','nir1','nir2','swir2','swir3']\n",
    "df['ndii'] = (df['nir1']-df['swir2'])/(df['nir1']+df['swir2'])\n",
    "# select just forest values\n",
    "df = df.loc[df.landcover == \"forest\",:]\n",
    "# create array in format\n",
    "lut = df[[\"fmc\",\"green\",\"red\",\"red_edge1\",\"red_edge2\",\"red_edge3\",\n",
    "          \"nir1\",\"nir2\",\"swir2\",\"swir3\",\"ndii\"]].values\n",
    "# the squares of the LUT\n",
    "squares = np.einsum(\"ij,ij->i\", lut[:, 1:], lut[:, 1:]) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mask of vegetation which has KTI of 3 or more, including only the koala distribution (from gov listing), which is reprojected to Albers/20m\n",
    "koala_trees = xr.open_rasterio('/g/data/xc0/user/IvanK/koala_area_variables/KTSI_NSW_5m_lam_VAO_INT_koalaAOI_compr.tif',\n",
    "                              chunks={'y': 2576,'x': 4259}).drop('band').squeeze('band')\n",
    "koala_trees.attrs['crs'] = 'EPSG:3577'\n",
    "\n",
    "# Create time dimension which includes every day since 2015 (ie whole Sentinel data period)\n",
    "time = pd.date_range(\"2021-04-01\", freq=\"D\", periods= 1 * 365)\n",
    "\n",
    "# Add time dimension to kti data mask, in a new xr dataset\n",
    "koala_trees = xr.Dataset({'koala_trees': koala_trees, 'time': time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the datacube using the 'like' attribute of load_ard, to take the spatial and temporal resolution of the kti dataset\n",
    "s2_cube = load_ard(dc=dc, products=['s2a_ard_granule','s2b_ard_granule'],\n",
    "                 like=koala_trees, measurements=[\"nbart_blue\",\"nbart_green\",\"nbart_red\",\n",
    "                         \"nbart_red_edge_1\",\"nbart_red_edge_2\",\"nbart_red_edge_3\",\n",
    "                         \"nbart_nir_1\",\"nbart_nir_2\",\"nbart_swir_2\",\"nbart_swir_3\"\n",
    "                        ], mask_pixel_quality=True,\n",
    "                 group_by='solar_day', dask_chunks = {'y': 2576,'x': 4259})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask the s2_cube using the 2d koala_trees data\n",
    "s2_cube = s2_cube.where(koala_trees.koala_trees == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## start FMC model\n",
    "\n",
    "refl = s2_cube[[\"nbart_green\",\"nbart_red\",\"nbart_red_edge_1\",\"nbart_red_edge_2\",\"nbart_red_edge_3\",\n",
    "         \"nbart_nir_1\",\"nbart_nir_2\",\"nbart_swir_2\",\"nbart_swir_3\"]].to_array().values/10000\n",
    "\n",
    "s2_cube['ndvi'] = ((s2_cube.nbart_nir_1-s2_cube.nbart_red)/(s2_cube.nbart_nir_1+s2_cube.nbart_red)) \n",
    "s2_cube['ndii'] = ((s2_cube.nbart_nir_1-s2_cube.nbart_swir_2)/(s2_cube.nbart_nir_1+s2_cube.nbart_swir_2))\n",
    "refl = np.concatenate([refl,s2_cube['ndii'].values[None,:,:]], axis=0)\n",
    "\n",
    "# create array frame\n",
    "canvas = np.ones(s2_cube['ndvi'].values.shape, dtype=np.float32) * np.nan\n",
    "# number of LUT values to consider in retrieval\n",
    "top_n = 150\n",
    "\n",
    "for t in range(s2_cube['ndvi'].values.shape[0]):\n",
    "\n",
    "    for j in range(s2_cube['ndvi'].values.shape[1]):\n",
    "\n",
    "        for i in range(s2_cube['ndvi'].values.shape[2]):\n",
    "            x = refl[:,t, j, i]\n",
    "#             m = forest_msk[j, i]\n",
    "            if np.isnan(s2_cube['ndvi'][t, j, i]) or s2_cube['ndvi'][t, j, i] < 0.15:\n",
    "#             if m != 1 or s2_cube['ndvi'][t, j, i] < 0.15: # already masked\n",
    "                continue\n",
    "\n",
    "            θ = -1 * (\n",
    "                np.einsum(\"ij,j->i\", lut[:, 1:], x)\n",
    "                / (np.einsum(\"i,i->\", x, x) ** 0.5 * squares)\n",
    "            )\n",
    "\n",
    "            idxs = np.argpartition(θ, top_n)[:top_n]\n",
    "            canvas[t, j, i] = np.median(lut[idxs, 0])\n",
    "s2_cube['FMC'] = (['time','y','x'], canvas) # TODO error: calculates FMC for pixels which have been masked in data retrieval(e.g clouds), so it is calculating FMC for nan in refl\n",
    "s2_cube = s2_cube.drop_vars([\"nbart_green\",\"nbart_red\",\"nbart_red_edge_1\",\"nbart_red_edge_2\",\"nbart_red_edge_3\",\n",
    "         \"nbart_nir_1\",\"nbart_nir_2\",\"nbart_swir_2\",\"nbart_swir_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_cube.to_netcdf('/g/data/xc0/user/IvanK/koala_area_variables/s2_FMC_koala_timeseries.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
